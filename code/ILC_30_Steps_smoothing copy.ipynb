{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import multiprocessing as mg\n",
    "import multiprocessing.pool\n",
    "# import pys2let as ps\n",
    "import random\n",
    "import string\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import s2fft\n",
    "import healpy as hp\n",
    "import numpy as np\n",
    "import s2wav\n",
    "import s2wav\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import skyclean\n",
    "from skyclean import CMB_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original Pixel Map size (1, 4, 7)\n",
      "original alm size (4, 7)\n",
      "padded alm size (8, 14)\n",
      "Scale: doubled map size (8, 15)\n",
      "(8, 15)\n"
     ]
    }
   ],
   "source": [
    "def mw_alm_2_hp_alm(MW_alm2, lmax):\n",
    "    # Initialize the 1D hp_alm array with the appropriate size\n",
    "    hp_alm1 = np.zeros(hp.Alm.getsize(lmax), dtype=np.complex128)\n",
    "        \n",
    "    for l in range(lmax + 1):\n",
    "        for m in range(-l, l + 1):\n",
    "            index = hp.Alm.getidx(lmax, l, abs(m))\n",
    "            if m < 0:\n",
    "                hp_alm1[index] = (-1)**m * np.conj(MW_alm2[l, lmax + m])\n",
    "            else:\n",
    "                hp_alm1[index] = MW_alm2[l, lmax + m]\n",
    "\n",
    "    return hp_alm1\n",
    "\n",
    "# Doubleworker\n",
    "\n",
    "## Loaded mw wavelet coefficient map\n",
    "\n",
    "## Covert to mw alm space\n",
    "\n",
    "## add zero to the mw alms  (Is it correct? or should I add zeros to the hp alm's and then convert to mw alm's)\n",
    "\n",
    "## Convert to from mw alm to mw map      (hp)\n",
    "\n",
    "\n",
    "def Single_Map_doubleworker(MW_Pix_Map):\n",
    "    '''\n",
    "    Input: MW_Pix_Map: list of mw maps at different scales \n",
    "    Each pixel map is a wavelet pixel map of shape (1, Lmax, 2*Lmax-1) (MW sampling, McEwen & Wiaux)\n",
    "    It is the output of s2wav.analysis\n",
    "    (Scale: 0, size (1, 4, 7))\n",
    "\n",
    "    Process:\n",
    "    1. Covert MW Pixel Map to MW alm space using s2fft.forward\n",
    "\n",
    "    2. Add zero to the mw alms  (Is it correct? or should I add zeros to the hp alm's and then convert to mw alm's)\n",
    "    by adding zeros to the MW alm's we are increasing the resolution of the map\n",
    "    Double the rows of the mw alms, since, the number of rows represents the L (level of detail)\n",
    "    \n",
    "    3. Convert mw alm to mw map \n",
    "    \n",
    "    '''\n",
    "    print(\"original Pixel Map size\", MW_Pix_Map.shape)\n",
    "    MW_alm = s2fft.forward(MW_Pix_Map, L = MW_Pix_Map.shape[1])\n",
    "    print(\"original alm size\", MW_alm.shape)\n",
    "    \n",
    "   \n",
    "    # print(\"Scale:\",i,\"original alm size\", MW_alm[i].shape)\n",
    "    padded_alm = np.zeros((MW_alm.shape[0]*2,MW_alm.shape[1]*2))\n",
    "    # stored_wavelet_coeffs_alm_doubled.append(skyclean.double_resolution(stored_wavelet_coeffs_alm[i]))\n",
    "    padded_alm[:MW_alm.shape[0], :MW_alm.shape[1]] = MW_alm\n",
    "    print(\"padded alm size\", padded_alm.shape)\n",
    "    MW_alm_doubled = padded_alm\n",
    "    \n",
    "    MW_Pix_Map_doubled = s2fft.inverse(MW_alm_doubled, L = MW_alm_doubled.shape[0])\n",
    "    print(\"Scale:\",\"doubled map size\", MW_Pix_Map_doubled.shape)\n",
    "\n",
    "    return MW_Pix_Map_doubled\n",
    "\n",
    "## Loaded mw wavelet coefficient map\n",
    "stored_wavelet_coeffs_pix = [np.load(f\"../convolution/wavelet_coefficient/wav_30_{i}.npy\", allow_pickle=True) for i in range(12)]\n",
    "stored_scaling_coeffs_pix = np.load(\"../convolution/scaling_coefficient/scal_30.npy\")\n",
    "\n",
    "\n",
    "# print(stored_wavelet_coeffs_pix[0].shape)\n",
    "stored_wavelet_coeffs_pix = stored_wavelet_coeffs_pix[:3]\n",
    "\n",
    "wavelet_MW_Pix_Map_doubled = Single_Map_doubleworker(stored_wavelet_coeffs_pix[0])\n",
    "\n",
    "# display(wavelet_MW_Pix_Map_doubled[0])\n",
    "# Why oen dimension is reduced?\n",
    "# Is it the spin?\n",
    "print(wavelet_MW_Pix_Map_doubled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothworker(MW_Map1, MW_Map2, smoothing_lmax, scale_fwhm):\n",
    "    '''\n",
    "    Input: MW_Map1, MW_Map2: same size MW pixel wavelet maps at different frequencies\n",
    "    output: R_map: smoothed coveriance map beteen MW_Map1 and MW_Map2\n",
    "    '''\n",
    "    # Get the real part of the map\n",
    "    map1 = np.real(MW_Map1)\n",
    "    map2 = np.real(MW_Map2)\n",
    "    # Covariance matrix\n",
    "    R = np.multiply(map1,map2) + 0.j #Add back in zero imaginary part\n",
    "    # print(\"R\", R.shape)\n",
    "\n",
    "    R_MW_alm = s2fft.forward(R, L = smoothing_lmax)\n",
    "    # print(\"R_MW_alm\", R_MW_alm.shape)\n",
    "    gauss_smooth = hp.gauss_beam(scale_fwhm,lmax=smoothing_lmax-1)\n",
    "    MW_alm_beam_convolved = np.zeros(R_MW_alm.shape, dtype=np.complex128)\n",
    "\n",
    "    # Convolve the MW alms with the beam\n",
    "    for i in range(R_MW_alm.shape[1]):\n",
    "        MW_alm_beam_convolved[:, i] = R_MW_alm[:, i] * gauss_smooth\n",
    "    \n",
    "    R_covariance_map = s2fft.inverse(MW_alm_beam_convolved, L = smoothing_lmax)\n",
    "\n",
    "    return R_covariance_map\n",
    "\n",
    "npix = hp.nside2npix(1<<(int(0.5*wavelet_MW_Pix_Map_doubled.shape[0])-1).bit_length())\n",
    "# (int(0.5*scale_lmax)-1).bit_length() calculates the number of bits necessary to represent the integer int(0.5*scale_lmax)-1 in binary.\n",
    "# 1 << (int(0.5*scale_lmax)-1).bit_length() performs a bitwise left shift, essentially calculating 2^(number of bits).\n",
    "scale_fwhm = 4.0 * math.sqrt(1200 / npix)\n",
    "R_covariance_map = smoothworker(wavelet_MW_Pix_Map_doubled, wavelet_MW_Pix_Map_doubled,wavelet_MW_Pix_Map_doubled.shape[0], scale_fwhm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 15)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_covariance_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ILC(MW_Pix_Map):\n",
    "\n",
    "    \n",
    "    Current_Wavelet_Map = MW_Pix_Map\n",
    "    \n",
    "    # Define the size of the smoothing beam \n",
    "    # 1200 pixels, size of the sphere\n",
    "    nsamp = 1200.0\n",
    "    lmax_at_scale_j = Current_Wavelet_Map.shape[0]\n",
    "    npix = hp.nside2npix(1<<(int(0.5*lmax_at_scale_j)-1).bit_length())\n",
    "    # (int(0.5*scale_lmax)-1).bit_length() calculates the number of bits necessary to represent the integer int(0.5*scale_lmax)-1 in binary.\n",
    "    # 1 << (int(0.5*scale_lmax)-1).bit_length() performs a bitwise left shift, essentially calculating 2^(number of bits).\n",
    "    scale_fwhm = 4.0 * math.sqrt(nsamp / npix)\n",
    "    # for high resolution maps, it is still the same number pixels sampled by the actual range is smaller.\n",
    "    # the beam will become narrow?\n",
    "    print(lmax_at_scale_j,npix, scale_fwhm)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2],[3,4]])\n",
    "b = np.array([[5,6],[7,8]])\n",
    "# display(a)\n",
    "# display(b)\n",
    "# display(np.multiply(a,b))\n",
    "# display(np.multiply(wavelet_MW_Pix_Map_doubled[0],wavelet_MW_Pix_Map_doubled[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ILC(MW_Pix_Map):\n",
    "\n",
    "    \n",
    "    Current_Wavelet_Map = MW_Pix_Map\n",
    "    \n",
    "    # Define the size of the smoothing beam \n",
    "    # 1200 pixels, size of the sphere\n",
    "    nsamp = 1200.0\n",
    "    lmax_at_scale_j = Current_Wavelet_Map.shape[0]\n",
    "    npix = hp.nside2npix(1<<(int(0.5*lmax_at_scale_j)-1).bit_length())\n",
    "    # (int(0.5*scale_lmax)-1).bit_length() calculates the number of bits necessary to represent the integer int(0.5*scale_lmax)-1 in binary.\n",
    "    # 1 << (int(0.5*scale_lmax)-1).bit_length() performs a bitwise left shift, essentially calculating 2^(number of bits).\n",
    "    scale_fwhm = 4.0 * math.sqrt(nsamp / npix)\n",
    "    # for high resolution maps, it is still the same number pixels sampled by the actual range is smaller.\n",
    "    # the beam will become very narrow.\n",
    "    print(lmax_at_scale_j,npix, scale_fwhm)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# ILC(wavelet_MW_Pix_Map_doubled)\n",
    "\n",
    "# print(wavelet_MW_Pix_Map_doubled.shape)\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
