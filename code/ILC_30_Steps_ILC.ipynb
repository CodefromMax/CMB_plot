{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import multiprocessing as mg\n",
    "import multiprocessing.pool\n",
    "# import pys2let as ps\n",
    "import random\n",
    "import string\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import s2fft\n",
    "import healpy as hp\n",
    "import numpy as np\n",
    "import s2wav\n",
    "import s2wav\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import skyclean\n",
    "from skyclean import CMB_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8, 15)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mw_alm_2_hp_alm(MW_alm, lmax):\n",
    "    '''MW_alm: 2D array of shape (Lmax, 2*Lmax-1) (MW sampling, McEwen & Wiaux)\n",
    "    '''\n",
    "    # Initialize the 1D hp_alm array with the appropriate size\n",
    "    hp_alm = np.zeros(hp.Alm.getsize(lmax), dtype=np.complex128)\n",
    "        \n",
    "    for l in range(lmax + 1):\n",
    "        for m in range(-l, l + 1):\n",
    "            index = hp.Alm.getidx(lmax, l, abs(m))\n",
    "            if m < 0:\n",
    "                hp_alm[index] = (-1)**m * np.conj(MW_alm[l, lmax + m])\n",
    "            else:\n",
    "                hp_alm[index] = MW_alm[l, lmax + m]\n",
    "\n",
    "    return hp_alm\n",
    "\n",
    "\n",
    "def Single_Map_doubleworker(MW_Pix_Map):\n",
    "    '''\n",
    "    Input: MW_Pix_Map: list of mw maps at different scales \n",
    "    Each pixel map is a wavelet pixel map of shape (1, Lmax, 2*Lmax-1) (MW sampling, McEwen & Wiaux)\n",
    "    It is the output of s2wav.analysis\n",
    "    (Scale: 0, size (1, 4, 7))\n",
    "\n",
    "    Process:\n",
    "    1. Covert MW Pixel Map to MW alm space using s2fft.forward\n",
    "\n",
    "    2. Add zero to the mw alms  (Is it correct? or should I add zeros to the hp alm's and then convert to mw alm's)\n",
    "    by adding zeros to the MW alm's we are increasing the resolution of the map\n",
    "    Double the rows of the mw alms, since, the number of rows represents the L (level of detail)\n",
    "    \n",
    "    3. Convert mw alm to mw map \n",
    "    \n",
    "    '''\n",
    "    # print(\"original Pixel Map size\", MW_Pix_Map.shape)\n",
    "    MW_alm = s2fft.forward(MW_Pix_Map, L = MW_Pix_Map.shape[1])\n",
    "    # print(\"original alm size\", MW_alm.shape)\n",
    "    \n",
    "   \n",
    "    # print(\"Scale:\",i,\"original alm size\", MW_alm[i].shape)\n",
    "    padded_alm = np.zeros((MW_alm.shape[0]*2,MW_alm.shape[1]*2))\n",
    "    # stored_wavelet_coeffs_alm_doubled.append(skyclean.double_resolution(stored_wavelet_coeffs_alm[i]))\n",
    "    padded_alm[:MW_alm.shape[0], :MW_alm.shape[1]] = MW_alm\n",
    "    # print(\"padded alm size\", padded_alm.shape)\n",
    "    MW_alm_doubled = padded_alm\n",
    "    \n",
    "    MW_Pix_Map_doubled = s2fft.inverse(MW_alm_doubled, L = MW_alm_doubled.shape[0])\n",
    "    # print(\"Scale:\",\"doubled map size\", MW_Pix_Map_doubled.shape)\n",
    "\n",
    "    return MW_Pix_Map_doubled\n",
    "\n",
    "\n",
    "def smoothed_covariance(MW_Map1, MW_Map2):\n",
    "    '''\n",
    "    Input: MW_Map1, MW_Map2: same size MW pixel wavelet maps at different frequencies\n",
    "    output: R_map: smoothed covariance map beteen MW_Map1 and MW_Map2\n",
    "    '''\n",
    "    smoothing_lmax = MW_Map1.shape[0]\n",
    "    # Get the real part of the map\n",
    "    map1 = np.real(MW_Map1)\n",
    "    map2 = np.real(MW_Map2)\n",
    "    # Covariance matrix\n",
    "    R_MW_Pixel_map = np.multiply(map1,map2) + 0.j #Add back in zero imaginary part\n",
    "    # print(\"R\", R_MW_Pixel_map.shape)\n",
    "\n",
    "    # smoothing in harmonic space for efficiency\n",
    "    R_MW_alm = s2fft.forward(R_MW_Pixel_map, L = smoothing_lmax)\n",
    "    # print(\"R_MW_alm\", R_MW_alm.shape)\n",
    "\n",
    "\n",
    "    nsamp = 1200.0\n",
    "    lmax_at_scale_j = R_MW_alm.shape[0]\n",
    "    npix = hp.nside2npix(1<<(int(0.5*lmax_at_scale_j)-1).bit_length())\n",
    "    # (int(0.5*scale_lmax)-1).bit_length() calculates the number of bits necessary to represent the integer int(0.5*scale_lmax)-1 in binary.\n",
    "    # 1 << (int(0.5*scale_lmax)-1).bit_length() performs a bitwise left shift, essentially calculating 2^(number of bits).\n",
    "    scale_fwhm = 4.0 * math.sqrt(nsamp / npix)\n",
    "    # for high resolution maps, it is still the same number pixels sampled by the actual range is smaller.\n",
    "    # the beam will become very narrow.\n",
    "\n",
    "\n",
    "    gauss_smooth = hp.gauss_beam(scale_fwhm,lmax=smoothing_lmax-1)\n",
    "    MW_alm_beam_convolved = np.zeros(R_MW_alm.shape, dtype=np.complex128)\n",
    "\n",
    "    # Convolve the MW alms with the beam\n",
    "    for i in range(R_MW_alm.shape[1]):\n",
    "        MW_alm_beam_convolved[:, i] = R_MW_alm[:, i] * gauss_smooth\n",
    "    \n",
    "    R_covariance_map = s2fft.inverse(MW_alm_beam_convolved, L = smoothing_lmax)\n",
    "\n",
    "    return R_covariance_map\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "## Loaded mw wavelet coefficient map\n",
    "stored_wavelet_coeffs_pix = [np.load(f\"../convolution/wavelet_coefficient/wav_30_{i}.npy\", allow_pickle=True) for i in range(12)]\n",
    "stored_scaling_coeffs_pix = np.load(\"../convolution/scaling_coefficient/scal_30.npy\")\n",
    "\n",
    "\n",
    "# print(stored_wavelet_coeffs_pix[0].shape)\n",
    "stored_wavelet_coeffs_pix = stored_wavelet_coeffs_pix[:3]\n",
    "\n",
    "wavelet_MW_Pix_Map_doubled = Single_Map_doubleworker(stored_wavelet_coeffs_pix[0])\n",
    "\n",
    "# display(wavelet_MW_Pix_Map_doubled[0])\n",
    "# Why oen dimension is reduced?\n",
    "# Is it the spin?\n",
    "print(wavelet_MW_Pix_Map_doubled.shape)\n",
    "\n",
    "\n",
    "R_covariance_map = smoothed_covariance(wavelet_MW_Pix_Map_doubled, wavelet_MW_Pix_Map_doubled)\n",
    "\n",
    "R_covariance_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1787170963.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_3962829/1787170963.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    this is a list of wavelet coefficient covariance matrix[]create a for loop structure\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "this is a list of wavelet coefficient covariance matrix[]create a for loop structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't want to store all the data in a dictionary \n",
    "# wavelet is wavelet, and alm is alm \n",
    "# we get them from the same function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def load_frequency_data(base_path, file_template, frequencies, scales=None):\n",
    "    \"\"\"\n",
    "    Load NumPy arrays from dynamically generated file paths for each frequency and scale.\n",
    "    \n",
    "    Args:\n",
    "        base_path (str): The base path where the files are located.\n",
    "        file_template (str): The template for the file names, with placeholders for frequency and scale.\n",
    "        frequencies (list): A list of frequency names.\n",
    "        scales_: A lists of scales.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary where keys are tuples of (frequency, scale) and values are loaded NumPy arrays.\n",
    "    \"\"\"\n",
    "    frequency_data = {}\n",
    "    for frequency in frequencies:\n",
    "        for scale in scales:\n",
    "            # Generate the file path using the template and the current frequency and scale\n",
    "            path = f\"{base_path}/{file_template.format(frequency, scale)}\"\n",
    "            try:\n",
    "                frequency_data[(frequency, scale)] = np.load(path, allow_pickle=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {path} for frequency {frequency} and scale {scale}: {e}\")\n",
    "    return frequency_data\n",
    "\n",
    "\n",
    "\n",
    "base_path = \"../convolution/wavelet_coefficient\"\n",
    "file_template = \"wav_{}_{}.npy\"\n",
    "frequencies = ['030', '070']\n",
    "scales = [0, 1, 2]\n",
    "\n",
    "original_wavelet_c_j = load_frequency_data(base_path, file_template, frequencies, scales)\n",
    "\n",
    "# for (frequency, scale), data in frequency_data.items():\n",
    "#     print(f\"Frequency: {frequency}, Scale: {scale}, Data shape: {data.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in frequencies:\n",
    "    for j in scales:\n",
    "        # print(frequency_data[(i,j)].shape)\n",
    "        wavelet_MW_Pix_Map_doubled = Single_Map_doubleworker(original_wavelet_c_j[(i,j)])\n",
    "        np.save(f\"../convolution/wavelet_coefficient_doubled/wav_{i}_{j}.npy\", wavelet_MW_Pix_Map_doubled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([('030', 0), ('030', 1), ('030', 2), ('070', 0), ('070', 1), ('070', 2)])\n",
      "Element at (scale 0, covariance of frequency 030 and frqeucny 030): (8, 15)\n",
      "Element at (scale 0, covariance of frequency 030 and frqeucny 070): (8, 15)\n",
      "Element at (scale 0, covariance of frequency 070 and frqeucny 070): (8, 15)\n",
      "Element at (scale 1, covariance of frequency 030 and frqeucny 030): (8, 15)\n",
      "Element at (scale 1, covariance of frequency 030 and frqeucny 070): (8, 15)\n",
      "Element at (scale 1, covariance of frequency 070 and frqeucny 070): (8, 15)\n",
      "Element at (scale 2, covariance of frequency 030 and frqeucny 030): (16, 31)\n",
      "Element at (scale 2, covariance of frequency 030 and frqeucny 070): (16, 31)\n",
      "Element at (scale 2, covariance of frequency 070 and frqeucny 070): (16, 31)\n"
     ]
    }
   ],
   "source": [
    "doubled_MW_wav_c_j = load_frequency_data(\"../convolution/wavelet_coefficient_doubled\", \"wav_{}_{}.npy\", frequencies, scales)\n",
    "print(doubled_MW_wav_c_j.keys())\n",
    "\n",
    "total_frequency = len(frequencies)\n",
    "convariance_matrix_all_freq = np.full((len(scales),total_frequency, total_frequency), None)\n",
    "# Go to each scale in each frequency\n",
    "# for i in frequencies:\n",
    "for j in scales:\n",
    "    # calculate the covariance matrix\n",
    "    for i in range(total_frequency):\n",
    "        for fq in range(i, total_frequency):\n",
    "            # print(f\"Element at ({i}, {fq}): {convariance_matrix_all_freq[j, i, fq]}\")\n",
    "            convariance_matrix_all_freq[j, i, fq] = smoothed_covariance(doubled_MW_wav_c_j[(frequencies[i],j)], doubled_MW_wav_c_j[(frequencies[fq],j)])\n",
    "            np.save(f\"../convolution/covariance_matrix/cov_{j}_{frequencies[i]}_{frequencies[fq]}.npy\", convariance_matrix_all_freq[j, i, fq])\n",
    "            print(f\"Element at (scale {j}, covariance of frequency {frequencies[i]} and frqeucny {frequencies[fq]}): {convariance_matrix_all_freq[j, i, fq].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[None, None],\n",
       "       [None, None]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_frequency = 2  # Size of the matrix\n",
    "convariance_matrix_all_freq = np.full((total_frequency, total_frequency), None)\n",
    "\n",
    "for i in range(total_frequency):\n",
    "    for j in range(i, total_frequency):\n",
    "        print(f\"Element at ({i}, {j}): {convariance_matrix_all_freq[i, j]}\")\n",
    "        convariance_matrix_all_freq[i, j] = smoothed_covariance(stored_wavelet_coeffs_pix[i], stored_wavelet_coeffs_pix[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4x4 matrix\n",
    "matrix = [\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 6, 7, 8],\n",
    "    [9, 10, 11, 12],\n",
    "    [13, 14, 15, 16]\n",
    "]\n",
    "\n",
    "n = len(matrix)  # Size of the matrix\n",
    "\n",
    "# Loop through the upper triangular part of the matrix\n",
    "for i in range(n):\n",
    "    for j in range(i, n):\n",
    "        print(f\"Element at ({i}, {j}): {matrix[i][j]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2],[3,4]])\n",
    "b = np.array([[5,6],[7,8]])\n",
    "# display(a)\n",
    "# display(b)\n",
    "# display(np.multiply(a,b))\n",
    "# display(np.multiply(wavelet_MW_Pix_Map_doubled[0],wavelet_MW_Pix_Map_doubled[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ILC(MW_Pix_Map):\n",
    "\n",
    "    \n",
    "    Current_Wavelet_Map = MW_Pix_Map\n",
    "    \n",
    "    # Define the size of the smoothing beam \n",
    "    # 1200 pixels, size of the sphere\n",
    "    nsamp = 1200.0\n",
    "    lmax_at_scale_j = Current_Wavelet_Map.shape[0]\n",
    "    npix = hp.nside2npix(1<<(int(0.5*lmax_at_scale_j)-1).bit_length())\n",
    "    # (int(0.5*scale_lmax)-1).bit_length() calculates the number of bits necessary to represent the integer int(0.5*scale_lmax)-1 in binary.\n",
    "    # 1 << (int(0.5*scale_lmax)-1).bit_length() performs a bitwise left shift, essentially calculating 2^(number of bits).\n",
    "    scale_fwhm = 4.0 * math.sqrt(nsamp / npix)\n",
    "    # for high resolution maps, it is still the same number pixels sampled by the actual range is smaller.\n",
    "    # the beam will become very narrow.\n",
    "    print(lmax_at_scale_j,npix, scale_fwhm)\n",
    "\n",
    "\n",
    "    # after smoothworker, 81 covariance maps \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# ILC(wavelet_MW_Pix_Map_doubled)\n",
    "\n",
    "# print(wavelet_MW_Pix_Map_doubled.shape)\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
