{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import multiprocessing as mg\n",
    "import multiprocessing.pool\n",
    "# import pys2let as ps\n",
    "import random\n",
    "import string\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import s2fft\n",
    "import healpy as hp\n",
    "import numpy as np\n",
    "import s2wav\n",
    "import s2wav\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import skyclean\n",
    "from skyclean import CMB_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale: 0 alm size (4, 7)\n",
      "Scale: 1 alm size (4, 7)\n",
      "Scale: 2 alm size (8, 15)\n",
      "Scale: 0 padded alm size (8, 14)\n",
      "Scale: 1 padded alm size (8, 14)\n",
      "Scale: 2 padded alm size (16, 30)\n",
      "Scale: 0 doubled map size (8, 15)\n",
      "Scale: 1 doubled map size (8, 15)\n",
      "Scale: 2 doubled map size (16, 31)\n"
     ]
    }
   ],
   "source": [
    "# Doubleworker\n",
    "\n",
    "## Loaded mw wavelet coefficient map\n",
    "\n",
    "## Covert to mw alm space\n",
    "\n",
    "## add zero to the mw alms  (Is it correct? or should I add zeros to the hp alm's and then convert to mw alm's)\n",
    "\n",
    "## Convert to from mw alm to mw map      (hp)\n",
    "\n",
    "\n",
    "def doubleworker_original(MW_Pix_Map):\n",
    "    '''\n",
    "    Input: MW_Pix_Map: list of mw maps at different scales \n",
    "    Each pixel map is a wavelet pixel map of shape (1, Lmax, 2*Lmax-1) (MW sampling, McEwen & Wiaux)\n",
    "    It is the output of s2wav.analysis\n",
    "    (Scale: 0, size (1, 4, 7))\n",
    "\n",
    "    Process:\n",
    "    1. Covert MW Pixel Map to MW alm space using s2fft.forward\n",
    "\n",
    "    2. Add zero to the mw alms  (Is it correct? or should I add zeros to the hp alm's and then convert to mw alm's)\n",
    "    by adding zeros to the MW alm's we are increasing the resolution of the map\n",
    "    Double the rows of the mw alms, since, the number of rows represents the L (level of detail)\n",
    "    \n",
    "    3. Convert mw alm to mw map \n",
    "    \n",
    "    '''\n",
    "    MW_alm = []\n",
    "\n",
    "    for i in range(len(MW_Pix_Map)):\n",
    "        # print(\"Scale:\",i,\"original MW Pixel Map size\", MW_Pix_Map[i].shape)\n",
    "        \n",
    "        # Use s2fft.forward to convert to mw alm space (L_max is the maxnumber of )\n",
    "        MW_alm.append(s2fft.forward(MW_Pix_Map[i], L = MW_Pix_Map[i].shape[1]))\n",
    "        print(\"Scale:\",i,\"alm size\", MW_alm[i].shape)\n",
    "    \n",
    "    MW_alm_doubled = []\n",
    "    \n",
    "    # for i in range(len(MW_alm)):\n",
    "    #     # print(\"Scale:\",i,\"original alm size\", MW_alm[i].shape)\n",
    "    #     padded_alm = np.zeros((MW_alm[i].shape[0]*2,MW_alm[i].shape[1]))\n",
    "    #     # stored_wavelet_coeffs_alm_doubled.append(skyclean.double_resolution(stored_wavelet_coeffs_alm[i]))\n",
    "    #     padded_alm[:MW_alm[i].shape[0], :] = MW_alm[i]\n",
    "    #     print(\"Scale:\",i,\"padded alm size\", padded_alm.shape)\n",
    "    #     MW_alm_doubled.append(padded_alm)\n",
    "    \n",
    "    for i in range(len(MW_alm)):\n",
    "        # print(\"Scale:\",i,\"original alm size\", MW_alm[i].shape)\n",
    "        padded_alm = np.zeros((MW_alm[i].shape[0]*2,MW_alm[i].shape[1]*2))\n",
    "        # stored_wavelet_coeffs_alm_doubled.append(skyclean.double_resolution(stored_wavelet_coeffs_alm[i]))\n",
    "        padded_alm[:MW_alm[i].shape[0], :MW_alm[i].shape[1]] = MW_alm[i]\n",
    "        print(\"Scale:\",i,\"padded alm size\", padded_alm.shape)\n",
    "        MW_alm_doubled.append(padded_alm)\n",
    "    \n",
    "    MW_Pix_Map_doubled = []\n",
    "\n",
    "    for i in range(len(MW_alm_doubled)):\n",
    "        # print(MW_alm_doubled[i].shape[0])\n",
    "        MW_Pix_Map_doubled.append(s2fft.inverse(MW_alm_doubled[i], L = MW_alm_doubled[i].shape[0]))\n",
    "        print(\"Scale:\",i,\"doubled map size\", MW_Pix_Map_doubled[i].shape)\n",
    "\n",
    "    return MW_Pix_Map_doubled\n",
    "\n",
    "## Loaded mw wavelet coefficient map\n",
    "stored_wavelet_coeffs_pix = [np.load(f\"../convolution/wavelet_coefficient/wav_30_{i}.npy\", allow_pickle=True) for i in range(12)]\n",
    "stored_scaling_coeffs_pix = np.load(\"../convolution/scaling_coefficient/scal_30.npy\")\n",
    "\n",
    "\n",
    "# print(stored_wavelet_coeffs_pix[0].shape)\n",
    "stored_wavelet_coeffs_pix = stored_wavelet_coeffs_pix[:3]\n",
    "\n",
    "wavelet_MW_Pix_Map_doubled = doubleworker(stored_wavelet_coeffs_pix)\n",
    "\n",
    "# display(wavelet_MW_Pix_Map_doubled[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original Pixel Map size (1, 4, 7)\n",
      "original alm size (4, 7)\n",
      "padded alm size (8, 14)\n",
      "Scale: doubled map size (8, 15)\n",
      "(8, 15)\n"
     ]
    }
   ],
   "source": [
    "# Doubleworker\n",
    "\n",
    "## Loaded mw wavelet coefficient map\n",
    "\n",
    "## Covert to mw alm space\n",
    "\n",
    "## add zero to the mw alms  (Is it correct? or should I add zeros to the hp alm's and then convert to mw alm's)\n",
    "\n",
    "## Convert to from mw alm to mw map      (hp)\n",
    "\n",
    "\n",
    "def Single_Map_doubleworker(MW_Pix_Map):\n",
    "    '''\n",
    "    Input: MW_Pix_Map: list of mw maps at different scales \n",
    "    Each pixel map is a wavelet pixel map of shape (1, Lmax, 2*Lmax-1) (MW sampling, McEwen & Wiaux)\n",
    "    It is the output of s2wav.analysis\n",
    "    (Scale: 0, size (1, 4, 7))\n",
    "\n",
    "    Process:\n",
    "    1. Covert MW Pixel Map to MW alm space using s2fft.forward\n",
    "\n",
    "    2. Add zero to the mw alms  (Is it correct? or should I add zeros to the hp alm's and then convert to mw alm's)\n",
    "    by adding zeros to the MW alm's we are increasing the resolution of the map\n",
    "    Double the rows of the mw alms, since, the number of rows represents the L (level of detail)\n",
    "    \n",
    "    3. Convert mw alm to mw map \n",
    "    \n",
    "    '''\n",
    "    print(\"original Pixel Map size\", MW_Pix_Map.shape)\n",
    "    MW_alm = s2fft.forward(MW_Pix_Map, L = MW_Pix_Map.shape[1])\n",
    "    print(\"original alm size\", MW_alm.shape)\n",
    "    \n",
    "   \n",
    "    # print(\"Scale:\",i,\"original alm size\", MW_alm[i].shape)\n",
    "    padded_alm = np.zeros((MW_alm.shape[0]*2,MW_alm.shape[1]*2))\n",
    "    # stored_wavelet_coeffs_alm_doubled.append(skyclean.double_resolution(stored_wavelet_coeffs_alm[i]))\n",
    "    padded_alm[:MW_alm.shape[0], :MW_alm.shape[1]] = MW_alm\n",
    "    print(\"padded alm size\", padded_alm.shape)\n",
    "    MW_alm_doubled = padded_alm\n",
    "    \n",
    "    MW_Pix_Map_doubled = s2fft.inverse(MW_alm_doubled, L = MW_alm_doubled.shape[0])\n",
    "    print(\"Scale:\",\"doubled map size\", MW_Pix_Map_doubled.shape)\n",
    "\n",
    "    return MW_Pix_Map_doubled\n",
    "\n",
    "## Loaded mw wavelet coefficient map\n",
    "stored_wavelet_coeffs_pix = [np.load(f\"../convolution/wavelet_coefficient/wav_30_{i}.npy\", allow_pickle=True) for i in range(12)]\n",
    "stored_scaling_coeffs_pix = np.load(\"../convolution/scaling_coefficient/scal_30.npy\")\n",
    "\n",
    "\n",
    "# print(stored_wavelet_coeffs_pix[0].shape)\n",
    "stored_wavelet_coeffs_pix = stored_wavelet_coeffs_pix[:3]\n",
    "\n",
    "wavelet_MW_Pix_Map_doubled = Single_Map_doubleworker(stored_wavelet_coeffs_pix[0])\n",
    "\n",
    "# display(wavelet_MW_Pix_Map_doubled[0])\n",
    "# Why oen dimension is reduced?\n",
    "# Is it the spin?\n",
    "print(wavelet_MW_Pix_Map_doubled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2],[3,4]])\n",
    "b = np.array([[5,6],[7,8]])\n",
    "# display(a)\n",
    "# display(b)\n",
    "# display(np.multiply(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(np.multiply(wavelet_MW_Pix_Map_doubled[0],wavelet_MW_Pix_Map_doubled[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ILC(MW_Pix_Map):\n",
    "\n",
    "    \n",
    "    Current_Wavelet_Map = MW_Pix_Map\n",
    "    \n",
    "    # Define the size of the smoothing beam \n",
    "    # 1200 pixels, size of the sphere\n",
    "    nsamp = 1200.0\n",
    "    lmax_at_scale_j = Current_Wavelet_Map.shape[0]\n",
    "    npix = hp.nside2npix(1<<(int(0.5*lmax_at_scale_j)-1).bit_length())\n",
    "    # (int(0.5*scale_lmax)-1).bit_length() calculates the number of bits necessary to represent the integer int(0.5*scale_lmax)-1 in binary.\n",
    "    # 1 << (int(0.5*scale_lmax)-1).bit_length() performs a bitwise left shift, essentially calculating 2^(number of bits).\n",
    "    scale_fwhm = 4.0 * math.sqrt(nsamp / npix)\n",
    "    # for high resolution maps, it is still the same number pixels sampled by the actual range is smaller.\n",
    "    # the beam will become very narrow.\n",
    "    print(lmax_at_scale_j,npix, scale_fwhm)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# ILC(wavelet_MW_Pix_Map_doubled)\n",
    "\n",
    "# print(wavelet_MW_Pix_Map_doubled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s2let_ilc(mapsextra): #mapsextra = (j,n)\n",
    "    print \"Running S2LET ILC on wavelet scale\", mapsextra[0], \"/\", jmax, \"direction\", mapsextra[1]+1, \"/\", ndir, \"\\n\"\n",
    "\n",
    "    if mapsextra[0] >= 0: #Wavelet scales\n",
    "        scale_lmax = wav_bandlims[mapsextra[0]]\n",
    "    else: #Scaling function\n",
    "        scale_lmax = int(scal_bandlims)\n",
    "    smoothing_lmax = 2*(scale_lmax-1)+1\n",
    "\n",
    "    #Doubling lmax for input maps with zero-padding\n",
    "    #Serial version\n",
    "    '''mapsdouble = np.zeros((nrows,ps.mw_size(smoothing_lmax)),dtype=np.complex128) #Pre-allocate array\n",
    "    for i in xrange(nrows):\n",
    "        mapsdouble[i,:] = doubleworker((mapsextra[0][i],mapsextra[1],smoothing_lmax,mapsextra[2]))'''\n",
    "    #Parallel version\n",
    "    mapsextra2 = [(mapsextra[0],mapsextra[1],i,scale_lmax,smoothing_lmax) for i in xrange(nmaps)]\n",
    "    print \"Forming pool\"\n",
    "    pool2 = mg.Pool(nprocess2)\n",
    "    print \"Farming out workers to run doubling function\"\n",
    "    double_output = pool2.map(doubleworker,mapsextra2)\n",
    "    print \"Have returned from doubling workers\\n\"\n",
    "    pool2.close()\n",
    "    pool2.join()\n",
    "    del pool2\n",
    "\n",
    "    #Calculate scale_fwhm for smoothing kernel\n",
    "    nsamp = 1200.\n",
    "    npix = hp.nside2npix(1<<(int(0.5*scale_lmax)-1).bit_length()) #Equivalent no. HEALPIX pixels\n",
    "    scale_fwhm = 4. * mh.sqrt(nsamp / npix)\n",
    "    \n",
    "    #TESTING larger covariance kernel\n",
    "    scale_fwhm = 15.*scale_fwhm\n",
    "    \n",
    "    #Smooth covariance matrices\n",
    "    #Serial version\n",
    "    '''Rsmoothflat = np.zeros_like(Rflat) #Pre-allocate array\n",
    "    for i in xrange(nindepelems):\n",
    "        Rsmoothflat[i,:] = smoothworker((Rflat[i],smoothing_lmax,mapsextra[2],gausssmooth,mapsextra[1],mapsextra[3],i,mapsextra[4]))\n",
    "    del Rflat'''\n",
    "    #Parallel version\n",
    "    nindepelems = int(nmaps*(nmaps+1)*.5) #No. indep. elements in symmetric covariance matrix\n",
    "    Rextra = [None]*nindepelems\n",
    "    k=0\n",
    "    for i in xrange(nmaps):\n",
    "        for j in xrange(i+1):\n",
    "            Rextra[k] = (mapsextra[0],mapsextra[1],i,j,smoothing_lmax,scale_fwhm)\n",
    "            k+=1\n",
    "    print \"Forming pool\"\n",
    "    pool3 = mg.Pool(nprocess3)\n",
    "    print \"Farming out workers to run smoothing function\"\n",
    "    R_output = pool3.map(smoothworker,Rextra)\n",
    "    print \"Have returned from smoothing workers\\n\"\n",
    "    pool3.close()\n",
    "    pool3.join()\n",
    "    del pool3\n",
    "\n",
    "    #Load R maps and form matrices\n",
    "    print \"Pre-allocating memory for complete covariance tensor\\n\"\n",
    "    Rsmooth = np.zeros((ps.mw_size(smoothing_lmax),nmaps,nmaps),dtype=np.float64) #Pre-allocate array\n",
    "    for i in xrange(nmaps):\n",
    "        for j in xrange(i+1):\n",
    "            if mapsextra[0] >= 0: #Wavelet scales\n",
    "                R_fits = wav_outfits_root + '_' + wavparam_code + str(mapsextra[0]) + '_n' + str(mapsextra[1]+1) + '_Rsmooth' + str(i + 9 - nmaps) + str(j + 9 - nmaps) +'.npy'\n",
    "            else: #Scaling function\n",
    "                R_fits = scal_outfits[:-4] + '_Rsmooth' + str(i + 9 - nmaps) + str(j + 9 - nmaps) +'.npy'\n",
    "            Rsmooth[:,i,j] = np.load(R_fits)\n",
    "            if i != j:\n",
    "                Rsmooth[:,j,i] = Rsmooth[:,i,j]\n",
    "\n",
    "    #Compute inverse covariance matrices\n",
    "    print \"Calculating inverse covariance matrices\\n\"\n",
    "    Rinv = np.linalg.inv(Rsmooth) #Parallel vers. slower!?- LARGEST MEMORY COST: 2*9*9*(8000^2)*complex128=0.2TB\n",
    "    del Rsmooth\n",
    "\n",
    "    #Compute weights vectors (at each pixel)\n",
    "    wknumer = np.sum(Rinv,axis=-1)\n",
    "    del Rinv\n",
    "    wkdenom = np.sum(wknumer,axis=-1)\n",
    "    wk = wknumer / wkdenom[:,None]\n",
    "    del wknumer,wkdenom\n",
    "\n",
    "    #Map loading within sub-process\n",
    "    mapsdouble = np.zeros((len(wk),len(wk[0])),dtype=np.float64) #Pre-allocate array\n",
    "    for i in xrange(nmaps):\n",
    "        if mapsextra[0] >= 0: #Wavelet scales\n",
    "            wav_fits = wav_fits_root[i + 9 - nmaps] + '_' + wavparam_code + str(mapsextra[0]) + '_n' + str(mapsextra[1]+1) + '_double.npy'\n",
    "        else: #Scaling function\n",
    "            wav_fits = scal_fits[i + 9 - nmaps][:-4] + '_double.npy'\n",
    "        mapsdouble[:,i] = np.real(np.load(wav_fits,mmap_mode='r')) #Throw away zero imaginary part\n",
    "\n",
    "    #Dot weights with maps (at each small pixel) - at double l(j)\n",
    "    finalmap = np.sum(np.multiply(wk,mapsdouble),axis=-1) + 0.j #Add back in zero imaginary part\n",
    "    del wk,mapsdouble\n",
    "    \n",
    "    #Downgrade resolution of MW maps\n",
    "    print \"Downgrading resolution of CMB wavelet map\"\n",
    "    finalmapalms = ps.lm2lm_hp(ps.map2alm_mw(finalmap,smoothing_lmax,spin),smoothing_lmax) #Come out in MW order - so converted to HPX order\n",
    "    del finalmap\n",
    "    if mapsextra[0] >= 0: #Wavelet scales\n",
    "        alms_fname = wav_outfits_root + '_' + wavparam_code + str(mapsextra[0]) + '_n' + str(mapsextra[1]+1) + '_alms.fits'\n",
    "    else: #Scaling function\n",
    "        alms_fname = scal_outfits[:-4] + '_alms.fits'\n",
    "    hp.write_alm(alms_fname,finalmapalms,lmax=scale_lmax-1,mmax=scale_lmax-1)\n",
    "    del finalmapalms\n",
    "    finalmapalmstruncate = hp.read_alm(alms_fname)\n",
    "    finalmaphalf = ps.alm2map_mw(ps.lm_hp2lm(finalmapalmstruncate,scale_lmax),scale_lmax,spin)\n",
    "    del finalmapalmstruncate\n",
    "    \n",
    "    #Saving output map\n",
    "    if mapsextra[0] >= 1: #0: #Wavelet scales\n",
    "        wav_outfits = wav_outfits_root + '_' + wavparam_code + str(mapsextra[0]) + '_n' + str(mapsextra[1]+1) + '.npy'\n",
    "    elif mapsextra[0] == 0: #FOR NEW SCALING FUNC\n",
    "        wav_outfits = wav_outfits_0 + '_' + wavparam_code + str(mapsextra[0]) + '_n' + str(mapsextra[1]+1) + '.npy'\n",
    "    else: #Scaling function\n",
    "        wav_outfits = scal_outfits[:-4] + '.npy'\n",
    "    np.save(wav_outfits,finalmaphalf)\n",
    "    del finalmaphalf\n",
    "\n",
    "    return 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
