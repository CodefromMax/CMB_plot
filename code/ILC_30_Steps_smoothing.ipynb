{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import multiprocessing as mg\n",
    "import multiprocessing.pool\n",
    "# import pys2let as ps\n",
    "import random\n",
    "import string\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import s2fft\n",
    "import healpy as hp\n",
    "import numpy as np\n",
    "import s2wav\n",
    "import s2wav\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import skyclean\n",
    "from skyclean import CMB_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original Pixel Map size (1, 4, 7)\n",
      "original alm size (4, 7)\n",
      "padded alm size (8, 14)\n",
      "Scale: doubled map size (8, 15)\n",
      "(8, 15)\n"
     ]
    }
   ],
   "source": [
    "def mw_alm_2_hp_alm(MW_alm2, lmax):\n",
    "    # Initialize the 1D hp_alm array with the appropriate size\n",
    "    hp_alm1 = np.zeros(hp.Alm.getsize(lmax), dtype=np.complex128)\n",
    "        \n",
    "    for l in range(lmax + 1):\n",
    "        for m in range(-l, l + 1):\n",
    "            index = hp.Alm.getidx(lmax, l, abs(m))\n",
    "            if m < 0:\n",
    "                hp_alm1[index] = (-1)**m * np.conj(MW_alm2[l, lmax + m])\n",
    "            else:\n",
    "                hp_alm1[index] = MW_alm2[l, lmax + m]\n",
    "\n",
    "    return hp_alm1\n",
    "\n",
    "# Doubleworker\n",
    "\n",
    "## Loaded mw wavelet coefficient map\n",
    "\n",
    "## Covert to mw alm space\n",
    "\n",
    "## add zero to the mw alms  (Is it correct? or should I add zeros to the hp alm's and then convert to mw alm's)\n",
    "\n",
    "## Convert to from mw alm to mw map      (hp)\n",
    "\n",
    "\n",
    "def Single_Map_doubleworker(MW_Pix_Map):\n",
    "    '''\n",
    "    Input: MW_Pix_Map: list of mw maps at different scales \n",
    "    Each pixel map is a wavelet pixel map of shape (1, Lmax, 2*Lmax-1) (MW sampling, McEwen & Wiaux)\n",
    "    It is the output of s2wav.analysis\n",
    "    (Scale: 0, size (1, 4, 7))\n",
    "\n",
    "    Process:\n",
    "    1. Covert MW Pixel Map to MW alm space using s2fft.forward\n",
    "\n",
    "    2. Add zero to the mw alms  (Is it correct? or should I add zeros to the hp alm's and then convert to mw alm's)\n",
    "    by adding zeros to the MW alm's we are increasing the resolution of the map\n",
    "    Double the rows of the mw alms, since, the number of rows represents the L (level of detail)\n",
    "    \n",
    "    3. Convert mw alm to mw map \n",
    "    \n",
    "    '''\n",
    "    print(\"original Pixel Map size\", MW_Pix_Map.shape)\n",
    "    MW_alm = s2fft.forward(MW_Pix_Map, L = MW_Pix_Map.shape[1])\n",
    "    print(\"original alm size\", MW_alm.shape)\n",
    "    \n",
    "   \n",
    "    # print(\"Scale:\",i,\"original alm size\", MW_alm[i].shape)\n",
    "    padded_alm = np.zeros((MW_alm.shape[0]*2,MW_alm.shape[1]*2))\n",
    "    # stored_wavelet_coeffs_alm_doubled.append(skyclean.double_resolution(stored_wavelet_coeffs_alm[i]))\n",
    "    padded_alm[:MW_alm.shape[0], :MW_alm.shape[1]] = MW_alm\n",
    "    print(\"padded alm size\", padded_alm.shape)\n",
    "    MW_alm_doubled = padded_alm\n",
    "    \n",
    "    MW_Pix_Map_doubled = s2fft.inverse(MW_alm_doubled, L = MW_alm_doubled.shape[0])\n",
    "    print(\"Scale:\",\"doubled map size\", MW_Pix_Map_doubled.shape)\n",
    "\n",
    "    return MW_Pix_Map_doubled\n",
    "\n",
    "## Loaded mw wavelet coefficient map\n",
    "stored_wavelet_coeffs_pix = [np.load(f\"../convolution/wavelet_coefficient/wav_30_{i}.npy\", allow_pickle=True) for i in range(12)]\n",
    "stored_scaling_coeffs_pix = np.load(\"../convolution/scaling_coefficient/scal_30.npy\")\n",
    "\n",
    "\n",
    "# print(stored_wavelet_coeffs_pix[0].shape)\n",
    "stored_wavelet_coeffs_pix = stored_wavelet_coeffs_pix[:3]\n",
    "\n",
    "wavelet_MW_Pix_Map_doubled = Single_Map_doubleworker(stored_wavelet_coeffs_pix[0])\n",
    "\n",
    "# display(wavelet_MW_Pix_Map_doubled[0])\n",
    "# Why oen dimension is reduced?\n",
    "# Is it the spin?\n",
    "print(wavelet_MW_Pix_Map_doubled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R (8, 15)\n",
      "R_MW_alm (8, 15)\n",
      "R_hp_alm (36,)\n",
      "R (8, 15)\n",
      "R_MW_alm (8, 15)\n",
      "R_hp_alm (36,)\n"
     ]
    }
   ],
   "source": [
    "def smoothworker(MW_Map1, MW_Map2, smoothing_lmax, scale_fwhm):\n",
    "    # Get the real part of the map\n",
    "    map1 = np.real(MW_Map1)\n",
    "    map2 = np.real(MW_Map2)\n",
    "    # Coveriance matrix\n",
    "    R = np.multiply(map1,map2) + 0.j #Add back in zero imaginary part\n",
    "    print(\"R\", R.shape)\n",
    "\n",
    "    R_MW_alm = s2fft.forward(R, L = smoothing_lmax)\n",
    "    print(\"R_MW_alm\", R_MW_alm.shape)\n",
    "\n",
    "    R_hp_alm = mw_alm_2_hp_alm(R_MW_alm,smoothing_lmax-1)\n",
    "    # R_hp_alm1 = mw_alm_2_hp_alm(R_MW_alm,smoothing_lmax-1)\n",
    "    print(\"R_hp_alm\", R_hp_alm.shape)\n",
    "\n",
    "    gauss_smooth = hp.gauss_beam(scale_fwhm,lmax=smoothing_lmax-1)\n",
    "    hp.almxfl(R_hp_alm,gauss_smooth,inplace=True) #Multiply by gaussian beam\n",
    "    # print(gauss_smooth.shape)\n",
    "    # print(\"R_hp_alm\", R_hp_alm.shape)\n",
    "\n",
    "    MW_alm_beam_convolved = np.zeros(R_MW_alm.shape, dtype=np.complex128)\n",
    "\n",
    "    for i in range(R_MW_alm.shape[1]):\n",
    "        MW_alm_beam_convolved[:, i] = R_MW_alm[:, i] * gauss_smooth\n",
    "    # CMB_data_30_pix_beam_deconvolved.shape\n",
    "\n",
    "    # print(R_hp_alm == R_hp_alm1)\n",
    "    return R_hp_alm, MW_alm_beam_convolved\n",
    "\n",
    "\n",
    "npix = hp.nside2npix(1<<(int(0.5*wavelet_MW_Pix_Map_doubled.shape[0])-1).bit_length())\n",
    "# (int(0.5*scale_lmax)-1).bit_length() calculates the number of bits necessary to represent the integer int(0.5*scale_lmax)-1 in binary.\n",
    "# 1 << (int(0.5*scale_lmax)-1).bit_length() performs a bitwise left shift, essentially calculating 2^(number of bits).\n",
    "scale_fwhm = 4.0 * math.sqrt(1200 / npix)\n",
    "smoothworker(wavelet_MW_Pix_Map_doubled, wavelet_MW_Pix_Map_doubled,wavelet_MW_Pix_Map_doubled.shape[0], scale_fwhm)\n",
    "\n",
    "hp_alm_1, MW_alm = smoothworker(wavelet_MW_Pix_Map_doubled, wavelet_MW_Pix_Map_doubled,wavelet_MW_Pix_Map_doubled.shape[0], scale_fwhm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.42214339e-040+3.40237899e-057j,\n",
       "       -4.48611920e-049+3.55088446e-065j,\n",
       "       -4.34207483e-064-4.79158275e-081j,\n",
       "        3.65686041e-088+1.90546914e-104j,\n",
       "        2.28946809e-119+2.65340099e-135j,\n",
       "       -1.56812203e-159-1.18453325e-174j,\n",
       "       -1.48336698e-206-2.23969144e-222j,\n",
       "        5.13630232e-261-1.91042402e-276j,\n",
       "       -1.81066533e-048-8.25506863e-065j,\n",
       "        4.80335685e-065-4.28400754e-080j,\n",
       "        6.85205340e-088+7.47681292e-104j,\n",
       "       -1.25055167e-119+6.49658658e-135j,\n",
       "       -5.75114723e-159-1.54463325e-174j,\n",
       "       -2.29659457e-206-2.56662597e-221j,\n",
       "        5.21747260e-276+9.33454136e-277j,\n",
       "        2.62130082e-065-4.17203505e-080j,\n",
       "        3.59319463e-088+1.10131227e-103j,\n",
       "       -1.08450252e-119+4.13280982e-135j,\n",
       "       -8.81746376e-159+2.50255719e-174j,\n",
       "        7.31054191e-206-1.44914783e-221j,\n",
       "       -2.07593507e-275-1.34962725e-276j,\n",
       "       -1.27038614e-088-7.14138760e-104j,\n",
       "       -2.47079766e-119+1.66374767e-135j,\n",
       "        6.23488842e-159+1.56471526e-175j,\n",
       "        6.54095343e-206-1.33702540e-221j,\n",
       "        2.51140957e-276+1.58997797e-276j,\n",
       "        3.37119413e-119+3.28459668e-135j,\n",
       "       -7.79971632e-159-1.08110636e-174j,\n",
       "       -5.74249357e-206+6.65956714e-222j,\n",
       "       -1.56199846e-275+4.52905539e-276j,\n",
       "       -4.15171382e-158+1.87863730e-174j,\n",
       "        9.62858469e-206-3.00022526e-222j,\n",
       "       -3.27397254e-275-6.58161125e-276j,\n",
       "        2.80718920e-205-3.93740518e-221j,\n",
       "        3.78847581e-276+3.41034870e-276j,\n",
       "       -1.39141904e-275-4.48037578e-276j])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 2.42214339e-040+3.40237899e-057j,\n",
       "       -4.48611920e-049+3.55088446e-065j,\n",
       "       -4.34207483e-064-4.79158275e-081j,\n",
       "        3.65686041e-088+1.90546914e-104j,\n",
       "        2.28946809e-119+2.65340099e-135j,\n",
       "       -1.56812203e-159-1.18453325e-174j,\n",
       "       -1.48336698e-206-2.23969144e-222j,\n",
       "        5.13630232e-261-1.91042402e-276j,\n",
       "       -1.81066533e-048-8.25506863e-065j,\n",
       "        4.80335685e-065-4.28400754e-080j,\n",
       "        6.85205340e-088+7.47681292e-104j,\n",
       "       -1.25055167e-119+6.49658658e-135j,\n",
       "       -5.75114723e-159-1.54463325e-174j,\n",
       "       -2.29659457e-206-2.56662597e-221j,\n",
       "        5.21747260e-276+9.33454136e-277j,\n",
       "        2.62130082e-065-4.17203505e-080j,\n",
       "        3.59319463e-088+1.10131227e-103j,\n",
       "       -1.08450252e-119+4.13280982e-135j,\n",
       "       -8.81746376e-159+2.50255719e-174j,\n",
       "        7.31054191e-206-1.44914783e-221j,\n",
       "       -2.07593507e-275-1.34962725e-276j,\n",
       "       -1.27038614e-088-7.14138760e-104j,\n",
       "       -2.47079766e-119+1.66374767e-135j,\n",
       "        6.23488842e-159+1.56471526e-175j,\n",
       "        6.54095343e-206-1.33702540e-221j,\n",
       "        2.51140957e-276+1.58997797e-276j,\n",
       "        3.37119413e-119+3.28459668e-135j,\n",
       "       -7.79971632e-159-1.08110636e-174j,\n",
       "       -5.74249357e-206+6.65956714e-222j,\n",
       "       -1.56199846e-275+4.52905539e-276j,\n",
       "       -4.15171382e-158+1.87863730e-174j,\n",
       "        9.62858469e-206-3.00022526e-222j,\n",
       "       -3.27397254e-275-6.58161125e-276j,\n",
       "        2.80718920e-205-3.93740518e-221j,\n",
       "        3.78847581e-276+3.41034870e-276j,\n",
       "       -1.39141904e-275-4.48037578e-276j])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hp_alm_mw =  mw_alm_2_hp_alm(MW_alm, wavelet_MW_Pix_Map_doubled.shape[0]-1)\n",
    "display(hp_alm_1)\n",
    "display(hp_alm_mw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.42214339e-040+3.40237899e-057j,\n",
       "       -4.48611920e-049+3.55088446e-065j,\n",
       "       -4.34207483e-064-4.79158275e-081j,\n",
       "        3.65686041e-088+1.90546914e-104j,\n",
       "        2.28946809e-119+2.65340099e-135j,\n",
       "       -1.56812203e-159-1.18453325e-174j,\n",
       "       -1.48336698e-206-2.23969144e-222j,\n",
       "        5.13630232e-261-1.91042402e-276j,\n",
       "       -1.81066533e-048-8.25506863e-065j,\n",
       "        4.80335685e-065-4.28400754e-080j,\n",
       "        6.85205340e-088+7.47681292e-104j,\n",
       "       -1.25055167e-119+6.49658658e-135j,\n",
       "       -5.75114723e-159-1.54463325e-174j,\n",
       "       -2.29659457e-206-2.56662597e-221j,\n",
       "        5.21747260e-276+9.33454136e-277j,\n",
       "        2.62130082e-065-4.17203505e-080j,\n",
       "        3.59319463e-088+1.10131227e-103j,\n",
       "       -1.08450252e-119+4.13280982e-135j,\n",
       "       -8.81746376e-159+2.50255719e-174j,\n",
       "        7.31054191e-206-1.44914783e-221j,\n",
       "       -2.07593507e-275-1.34962725e-276j,\n",
       "       -1.27038614e-088-7.14138760e-104j,\n",
       "       -2.47079766e-119+1.66374767e-135j,\n",
       "        6.23488842e-159+1.56471526e-175j,\n",
       "        6.54095343e-206-1.33702540e-221j,\n",
       "        2.51140957e-276+1.58997797e-276j,\n",
       "        3.37119413e-119+3.28459668e-135j,\n",
       "       -7.79971632e-159-1.08110636e-174j,\n",
       "       -5.74249357e-206+6.65956714e-222j,\n",
       "       -1.56199846e-275+4.52905539e-276j,\n",
       "       -4.15171382e-158+1.87863730e-174j,\n",
       "        9.62858469e-206-3.00022526e-222j,\n",
       "       -3.27397254e-275-6.58161125e-276j,\n",
       "        2.80718920e-205-3.93740518e-221j,\n",
       "        3.78847581e-276+3.41034870e-276j,\n",
       "       -1.39141904e-275-4.48037578e-276j])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 2.42214339e-040+0.j, -4.48611920e-049+0.j, -4.34207483e-064+0.j,\n",
       "        3.65686041e-088+0.j,  2.28946809e-119+0.j, -1.56812203e-159+0.j,\n",
       "       -1.48336698e-206+0.j,  5.13630232e-261+0.j, -1.81066533e-048+0.j,\n",
       "        4.80335685e-065+0.j,  6.85205340e-088+0.j, -1.25055167e-119+0.j,\n",
       "       -5.75114723e-159+0.j, -2.29659457e-206+0.j,  5.21747260e-276+0.j,\n",
       "        2.62130082e-065+0.j,  3.59319463e-088+0.j, -1.08450252e-119+0.j,\n",
       "       -8.81746376e-159+0.j,  7.31054191e-206+0.j, -2.07593507e-275+0.j,\n",
       "       -1.27038614e-088+0.j, -2.47079766e-119+0.j,  6.23488842e-159+0.j,\n",
       "        6.54095343e-206+0.j,  2.51140957e-276+0.j,  3.37119413e-119+0.j,\n",
       "       -7.79971632e-159+0.j, -5.74249357e-206+0.j, -1.56199846e-275+0.j,\n",
       "       -4.15171382e-158+0.j,  9.62858469e-206+0.j, -3.27397254e-275+0.j,\n",
       "        2.80718920e-205+0.j,  3.78847581e-276+0.j, -1.39141904e-275+0.j])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hp_alm_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(...)? (3490765726.py, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_3953509/3490765726.py\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    print \"Synthesising smoothed covariance map for element\", i[2], \",\", i[3]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(...)?\n"
     ]
    }
   ],
   "source": [
    "def original_smoothworker(i): #(j,n,map_index1,map_index2,smoothing_lmax,scale_fwhm) [map_index2<=map_index1]\n",
    "    print (\"Smoothing independent covariance element\", i[2], \",\", i[3])\n",
    "\n",
    "    #Map loading within sub-process\n",
    "    if i[0] >= 0: #Wavelet scales\n",
    "        wav_fits1 = wav_fits_root[i[2]] + '_' + wavparam_code + str(i[0]) + '_n' + str(i[1]+1) + '_double.npy'\n",
    "        wav_fits2 = wav_fits_root[i[3]] + '_' + wavparam_code + str(i[0]) + '_n' + str(i[1]+1) + '_double.npy'\n",
    "    else: #Scaling function\n",
    "        wav_fits1 = scal_fits[i[2]][:-4] + '_double.npy'\n",
    "        wav_fits2 = scal_fits[i[3]][:-4] + '_double.npy'\n",
    "    map1 = np.real(np.load(wav_fits1,mmap_mode='r')) #Throw away zero imaginary part\n",
    "    map2 = np.real(np.load(wav_fits2,mmap_mode='r'))\n",
    "    R = np.multiply(map1,map2) + 0.j #Add back in zero imaginary part\n",
    "    del map1,map2\n",
    "\n",
    "    alms = ps.lm2lm_hp(ps.map2alm_mw(R,i[4],spin),i[4]) #No pixwin correct. with MW - calc alms to smooth - come out in MW order - so converted to HPX order\n",
    "    del R\n",
    "    gausssmooth = hp.gauss_beam(i[5],lmax=i[4]-1)\n",
    "    hp.almxfl(alms,gausssmooth,inplace=True) #Multiply by gaussian beam\n",
    "\n",
    "    print \"Synthesising smoothed covariance map for element\", i[2], \",\", i[3]\n",
    "    Rsmooth = np.real(ps.alm2map_mw(ps.lm_hp2lm(alms,i[4]),i[4],spin)) #Throw away zero imaginary part - input alm's in MW order\n",
    "    del alms\n",
    "    \n",
    "    #SAVE smoothed covariance\n",
    "    if i[0] >= 0: #Wavelet scales\n",
    "        R_fits = wav_outfits_root + '_' + wavparam_code + str(i[0]) + '_n' + str(i[1]+1) + '_Rsmooth' + str(i[2]) + str(i[3]) +'.npy'\n",
    "    else: #Scaling function\n",
    "        R_fits = scal_outfits[:-4] + '_Rsmooth' + str(i[2]) + str(i[3]) +'.npy'\n",
    "    np.save(R_fits,Rsmooth)\n",
    "    del Rsmooth\n",
    "    \n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2],[3,4]])\n",
    "b = np.array([[5,6],[7,8]])\n",
    "# display(a)\n",
    "# display(b)\n",
    "# display(np.multiply(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(np.multiply(wavelet_MW_Pix_Map_doubled[0],wavelet_MW_Pix_Map_doubled[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ILC(MW_Pix_Map):\n",
    "\n",
    "    \n",
    "    Current_Wavelet_Map = MW_Pix_Map\n",
    "    \n",
    "    # Define the size of the smoothing beam \n",
    "    # 1200 pixels, size of the sphere\n",
    "    nsamp = 1200.0\n",
    "    lmax_at_scale_j = Current_Wavelet_Map.shape[0]\n",
    "    npix = hp.nside2npix(1<<(int(0.5*lmax_at_scale_j)-1).bit_length())\n",
    "    # (int(0.5*scale_lmax)-1).bit_length() calculates the number of bits necessary to represent the integer int(0.5*scale_lmax)-1 in binary.\n",
    "    # 1 << (int(0.5*scale_lmax)-1).bit_length() performs a bitwise left shift, essentially calculating 2^(number of bits).\n",
    "    scale_fwhm = 4.0 * math.sqrt(nsamp / npix)\n",
    "    # for high resolution maps, it is still the same number pixels sampled by the actual range is smaller.\n",
    "    # the beam will become very narrow.\n",
    "    print(lmax_at_scale_j,npix, scale_fwhm)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# ILC(wavelet_MW_Pix_Map_doubled)\n",
    "\n",
    "# print(wavelet_MW_Pix_Map_doubled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s2let_ilc(mapsextra): #mapsextra = (j,n)\n",
    "    print \"Running S2LET ILC on wavelet scale\", mapsextra[0], \"/\", jmax, \"direction\", mapsextra[1]+1, \"/\", ndir, \"\\n\"\n",
    "\n",
    "    if mapsextra[0] >= 0: #Wavelet scales\n",
    "        scale_lmax = wav_bandlims[mapsextra[0]]\n",
    "    else: #Scaling function\n",
    "        scale_lmax = int(scal_bandlims)\n",
    "    smoothing_lmax = 2*(scale_lmax-1)+1\n",
    "\n",
    "    #Doubling lmax for input maps with zero-padding\n",
    "    #Serial version\n",
    "    '''mapsdouble = np.zeros((nrows,ps.mw_size(smoothing_lmax)),dtype=np.complex128) #Pre-allocate array\n",
    "    for i in xrange(nrows):\n",
    "        mapsdouble[i,:] = doubleworker((mapsextra[0][i],mapsextra[1],smoothing_lmax,mapsextra[2]))'''\n",
    "    #Parallel version\n",
    "    mapsextra2 = [(mapsextra[0],mapsextra[1],i,scale_lmax,smoothing_lmax) for i in xrange(nmaps)]\n",
    "    print \"Forming pool\"\n",
    "    pool2 = mg.Pool(nprocess2)\n",
    "    print \"Farming out workers to run doubling function\"\n",
    "    double_output = pool2.map(doubleworker,mapsextra2)\n",
    "    print \"Have returned from doubling workers\\n\"\n",
    "    pool2.close()\n",
    "    pool2.join()\n",
    "    del pool2\n",
    "\n",
    "    #Calculate scale_fwhm for smoothing kernel\n",
    "    nsamp = 1200.\n",
    "    npix = hp.nside2npix(1<<(int(0.5*scale_lmax)-1).bit_length()) #Equivalent no. HEALPIX pixels\n",
    "    scale_fwhm = 4. * mh.sqrt(nsamp / npix)\n",
    "    \n",
    "    #TESTING larger covariance kernel\n",
    "    scale_fwhm = 15.*scale_fwhm\n",
    "    \n",
    "    #Smooth covariance matrices\n",
    "    #Serial version\n",
    "    '''Rsmoothflat = np.zeros_like(Rflat) #Pre-allocate array\n",
    "    for i in xrange(nindepelems):\n",
    "        Rsmoothflat[i,:] = smoothworker((Rflat[i],smoothing_lmax,mapsextra[2],gausssmooth,mapsextra[1],mapsextra[3],i,mapsextra[4]))\n",
    "    del Rflat'''\n",
    "    #Parallel version\n",
    "    nindepelems = int(nmaps*(nmaps+1)*.5) #No. indep. elements in symmetric covariance matrix\n",
    "    Rextra = [None]*nindepelems\n",
    "    k=0\n",
    "    for i in xrange(nmaps):\n",
    "        for j in xrange(i+1):\n",
    "            Rextra[k] = (mapsextra[0],mapsextra[1],i,j,smoothing_lmax,scale_fwhm)\n",
    "            k+=1\n",
    "    print \"Forming pool\"\n",
    "    pool3 = mg.Pool(nprocess3)\n",
    "    print \"Farming out workers to run smoothing function\"\n",
    "    R_output = pool3.map(smoothworker,Rextra)\n",
    "    print \"Have returned from smoothing workers\\n\"\n",
    "    pool3.close()\n",
    "    pool3.join()\n",
    "    del pool3\n",
    "\n",
    "    #Load R maps and form matrices\n",
    "    print \"Pre-allocating memory for complete covariance tensor\\n\"\n",
    "    Rsmooth = np.zeros((ps.mw_size(smoothing_lmax),nmaps,nmaps),dtype=np.float64) #Pre-allocate array\n",
    "    for i in xrange(nmaps):\n",
    "        for j in xrange(i+1):\n",
    "            if mapsextra[0] >= 0: #Wavelet scales\n",
    "                R_fits = wav_outfits_root + '_' + wavparam_code + str(mapsextra[0]) + '_n' + str(mapsextra[1]+1) + '_Rsmooth' + str(i + 9 - nmaps) + str(j + 9 - nmaps) +'.npy'\n",
    "            else: #Scaling function\n",
    "                R_fits = scal_outfits[:-4] + '_Rsmooth' + str(i + 9 - nmaps) + str(j + 9 - nmaps) +'.npy'\n",
    "            Rsmooth[:,i,j] = np.load(R_fits)\n",
    "            if i != j:\n",
    "                Rsmooth[:,j,i] = Rsmooth[:,i,j]\n",
    "\n",
    "    #Compute inverse covariance matrices\n",
    "    print \"Calculating inverse covariance matrices\\n\"\n",
    "    Rinv = np.linalg.inv(Rsmooth) #Parallel vers. slower!?- LARGEST MEMORY COST: 2*9*9*(8000^2)*complex128=0.2TB\n",
    "    del Rsmooth\n",
    "\n",
    "    #Compute weights vectors (at each pixel)\n",
    "    wknumer = np.sum(Rinv,axis=-1)\n",
    "    del Rinv\n",
    "    wkdenom = np.sum(wknumer,axis=-1)\n",
    "    wk = wknumer / wkdenom[:,None]\n",
    "    del wknumer,wkdenom\n",
    "\n",
    "    #Map loading within sub-process\n",
    "    mapsdouble = np.zeros((len(wk),len(wk[0])),dtype=np.float64) #Pre-allocate array\n",
    "    for i in xrange(nmaps):\n",
    "        if mapsextra[0] >= 0: #Wavelet scales\n",
    "            wav_fits = wav_fits_root[i + 9 - nmaps] + '_' + wavparam_code + str(mapsextra[0]) + '_n' + str(mapsextra[1]+1) + '_double.npy'\n",
    "        else: #Scaling function\n",
    "            wav_fits = scal_fits[i + 9 - nmaps][:-4] + '_double.npy'\n",
    "        mapsdouble[:,i] = np.real(np.load(wav_fits,mmap_mode='r')) #Throw away zero imaginary part\n",
    "\n",
    "    #Dot weights with maps (at each small pixel) - at double l(j)\n",
    "    finalmap = np.sum(np.multiply(wk,mapsdouble),axis=-1) + 0.j #Add back in zero imaginary part\n",
    "    del wk,mapsdouble\n",
    "    \n",
    "    #Downgrade resolution of MW maps\n",
    "    print \"Downgrading resolution of CMB wavelet map\"\n",
    "    finalmapalms = ps.lm2lm_hp(ps.map2alm_mw(finalmap,smoothing_lmax,spin),smoothing_lmax) #Come out in MW order - so converted to HPX order\n",
    "    del finalmap\n",
    "    if mapsextra[0] >= 0: #Wavelet scales\n",
    "        alms_fname = wav_outfits_root + '_' + wavparam_code + str(mapsextra[0]) + '_n' + str(mapsextra[1]+1) + '_alms.fits'\n",
    "    else: #Scaling function\n",
    "        alms_fname = scal_outfits[:-4] + '_alms.fits'\n",
    "    hp.write_alm(alms_fname,finalmapalms,lmax=scale_lmax-1,mmax=scale_lmax-1)\n",
    "    del finalmapalms\n",
    "    finalmapalmstruncate = hp.read_alm(alms_fname)\n",
    "    finalmaphalf = ps.alm2map_mw(ps.lm_hp2lm(finalmapalmstruncate,scale_lmax),scale_lmax,spin)\n",
    "    del finalmapalmstruncate\n",
    "    \n",
    "    #Saving output map\n",
    "    if mapsextra[0] >= 1: #0: #Wavelet scales\n",
    "        wav_outfits = wav_outfits_root + '_' + wavparam_code + str(mapsextra[0]) + '_n' + str(mapsextra[1]+1) + '.npy'\n",
    "    elif mapsextra[0] == 0: #FOR NEW SCALING FUNC\n",
    "        wav_outfits = wav_outfits_0 + '_' + wavparam_code + str(mapsextra[0]) + '_n' + str(mapsextra[1]+1) + '.npy'\n",
    "    else: #Scaling function\n",
    "        wav_outfits = scal_outfits[:-4] + '.npy'\n",
    "    np.save(wav_outfits,finalmaphalf)\n",
    "    del finalmaphalf\n",
    "\n",
    "    return 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
